{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277c95df",
   "metadata": {},
   "source": [
    "# **REMOTE PHOTOPLETHYSMOGRAPHY (rPPG)**\n",
    "\n",
    "## IMPORTS Y CREACIÓN DEL ENTORNO PARA EL PROYECTO\n",
    "\n",
    "Se va a crear un nuevo environment utilizando **_Anaconda Prompt_** con las dependencias necesarias y únicas para la correcta realización del proyecto."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6f932a7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "conda create --name rPPG python=3.10\n",
    "conda activate rPPG\n",
    "pip install opencv-python mediapipe numpy scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef67df",
   "metadata": {},
   "source": [
    "Ya con las instalaciones y el environment creado, se va a proceder a la importación de las librerías necesarias para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62c0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import signal\n",
    "from scipy.fft import rfft, rfftfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc28cb",
   "metadata": {},
   "source": [
    "## REMOTE HEARD FRECUENCY\n",
    "\n",
    "Se va a capturar la frecuencia cardiaca a través de la WebCam del dispositivo.\n",
    "\n",
    "**Limitaciones y Consideraciones técnicas:**\n",
    "\n",
    "Aunque el sistema implementa algoritmos robustos como **POS (Plane-Orthogonal-to-Skin)** y segmentación **Multi-ROI**, la fotoplestimografía remota presenta limitaciones inherentes que dependen del entorno y la fisiología del sujeto.\n",
    "\n",
    "- **Iluminación y Relación Señal-Ruido (SNR):** El sistema no mide directamente el flujo sanguíneo, sino las variaciones sutiles en la absorción de luz. Por tanto, la calidad de la señal depende estrictamente de la fuente lumínica:\n",
    "\n",
    "    - **Baja iluminación:** El sensor de la cámara aumenta ganancia (ISO) automáticamente, introduciendo ruido de disparo (shot noise) y ruido térmico granular que enmascara la componente AC (pulsátil) de la señal cardíaca.\n",
    "\n",
    "    - **_Aliasing_ por iluminación artificial:** Fuentes de luz fluorescente aintiguas con parpadeo perceptible (50/60Hz) pueden introducir armónicos en el espectro de frecuencias que, por *aliasing* se podrían interpretar como latidos cardíacos si no se filtran adecuadamente.\n",
    "\n",
    "- **Variabilidad fisiológica y fototipos de piel:** La eficacia del algoritmo varía según diferentes grupos étnicos y características físicas del sujeto:\n",
    "\n",
    "    - **Fototipos altos:** Las pieles con mayor concentración de melanina absorben mayor cantidad de luz, reduciendo así la intensidad de la luz reflejada y disminuyendo en consecuencia la amplitud de la señal PPG. El resultado de lo anterior es que la **Relación Señal-Ruido (SNR)** es más baja comparada a la obtenida en pieles claras. Como solución, se puede implementar mayor iluminación o que la misma sea más intensa para obtener resultados fiables.\n",
    "\n",
    "    - **Oclusiones faciales:** El modelo utiliza tanto la frente como las mejillas, por lo tanto, si el individuo posee vello facial denso, gafas de montura muy gruesa, flequillos o cualquier objeto que interfiera directamente en estas zonas, se reduce el área efectiva de la ROI (Región de Interés).\n",
    "\n",
    "- **Artefactos de movimiento:** Aunque se implementa el algormito de proyección ortogonal (POS), si se suceden movimientos bruscos como hablar o gesticular se introducen cambios no lineales en la reflexión de la luz que no pueden ser cancelados totalmente por el modelo matemático lineal.\n",
    "\n",
    "    - **Restricción:** El individuo debe mantenerse a una posición relativamente estática para garantizar una precisión óptima.\n",
    "\n",
    "- **Latencia en la inicialización:** El sistema hace uso de un buffer temporal para realizar el análisis en el dominio de la frecuencia (FFT).\n",
    "\n",
    "    - **Cold Start:** El sistema tiene un retardo inicial de aproximadamente 5/6 segundos (viene dado por el tamaño del buffer) desde que se detecta la cara hasta que se encuentra el primer dato fiable, impidiendo así la medición instantánea.\n",
    "\n",
    "- **Limitaciones Hardware:**\n",
    "\n",
    "    - **Compresión de Video:** Muchas webcams comprimen el video en tiempo real. Los artefactos de compresión pueden alterar lso valores de color de los píxeles, suavisando los micro-cambios de color necesarios para la rPPG.\n",
    "\n",
    "    - **Jitter de FPS:** Si la CPU está saturada, la tasa de frames puede no ser constante. Aunque el código recalcula lso FPS dinámicamente, caídas drásticas afectarán la precisión de la **Transformada de Fourier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32b78dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Sistema Biométrico Robusto...\n",
      "Manten tu cara iluminada y dentro de los recuadros verdes.\n"
     ]
    }
   ],
   "source": [
    "class RobustHeartRateDetector:\n",
    "    def __init__(self):\n",
    "        # --- CONFIGURACIÓN DE MEDIAPIPE ---\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=False,\n",
    "            min_detection_confidence=0.6,\n",
    "            min_tracking_confidence=0.6\n",
    "        )\n",
    "        \n",
    "        # --- PARÁMETROS DEL SISTEMA ---\n",
    "        self.BUFFER_SIZE = 160     # Ventana de ~5.3 segundos a 30fps\n",
    "        self.FS = 30.0             # Frecuencia de muestreo estimada (se recalcula)\n",
    "        \n",
    "        # Buffers de datos\n",
    "        self.rgb_buffer = []       # Almacena tuplas (R, G, B) promedio\n",
    "        self.times_buffer = []     # Tiempos de captura\n",
    "        self.bpm_history = []      # Para suavizar la lectura final\n",
    "        \n",
    "        self.current_bpm = 0.0\n",
    "        self.is_stable = False     # Bandera para indicar si la lectura es fiable\n",
    "\n",
    "    def setup_camera(self):\n",
    "        \"\"\"Intenta configurar la cámara para desactivar auto-ajustes.\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        # Intentar desactivar auto-exposición (0.25/0.75 suele ser manual en algunas cams)\n",
    "        # Nota: Esto varía mucho según la marca de la webcam.\n",
    "        cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25) \n",
    "        cap.set(cv2.CAP_PROP_EXPOSURE, -5.0) # Valor bajo para evitar saturación\n",
    "        \n",
    "        # Desactivar auto-foco\n",
    "        cap.set(cv2.CAP_PROP_AUTOFOCUS, 0)\n",
    "        \n",
    "        return cap\n",
    "\n",
    "    def get_multi_roi_color(self, frame, landmarks):\n",
    "        \"\"\"\n",
    "        Extrae el promedio RGB combinado de Frente y Mejillas.\n",
    "        Usa una máscara para ser más preciso.\n",
    "        \"\"\"\n",
    "        h, w, c = frame.shape\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        \n",
    "        # Definir polígonos de las ROIs usando índices de MediaPipe\n",
    "        # Frente, Mejilla Izq, Mejilla Der\n",
    "        rois_indices = [\n",
    "            [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109], # Contorno cara simplificado\n",
    "            [151, 108, 69, 104, 68, 71],    # Frente (aprox)\n",
    "            [330, 347, 346, 352],           # Mejilla Izq\n",
    "            [101, 118, 117, 123]            # Mejilla Der\n",
    "        ]\n",
    "        \n",
    "        # Dibujar ROIs visuales (solo mejillas y frente para simplificar la media)\n",
    "        # Índices específicos para obtener piel limpia\n",
    "        roi_points_list = [\n",
    "            [109, 69, 104, 108, 151, 337, 299, 333, 298], # Frente extendida\n",
    "            [266, 425, 435, 346, 347, 329, 371],          # Mejilla Izquierda\n",
    "            [36, 205, 215, 117, 118, 100, 142]            # Mejilla Derecha\n",
    "        ]\n",
    "        \n",
    "        combined_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        \n",
    "        for region in roi_points_list:\n",
    "            points = np.array([[int(landmarks.landmark[i].x * w), int(landmarks.landmark[i].y * h)] for i in region], np.int32)\n",
    "            cv2.fillPoly(combined_mask, [points], 255)\n",
    "            # Dibujar contorno verde en el frame para feedback\n",
    "            cv2.polylines(frame, [points], True, (0, 255, 0), 1)\n",
    "\n",
    "        # Extraer promedio de color donde la máscara es blanca\n",
    "        mean_color = cv2.mean(frame, mask=combined_mask)[:3] # (B, G, R)\n",
    "        return mean_color # Devuelve (B, G, R)\n",
    "\n",
    "    def pos_algorithm(self, rgb_array):\n",
    "        \"\"\"\n",
    "        Implementación robusta del algoritmo POS (Wang et al., 2016).\n",
    "        Proyecta la señal RGB en un plano ortogonal al tono de piel para eliminar movimiento.\n",
    "        \"\"\"\n",
    "        # Entrada: rgb_array shape (N_frames, 3) -> Convertir a (3, N_frames)\n",
    "        C = rgb_array.T \n",
    "        \n",
    "        # 1. Normalización temporal (Dividir por la media para quitar brillo DC)\n",
    "        mean_color = np.mean(C, axis=1, keepdims=True)\n",
    "        Cn = C / (mean_color + 1e-6) - 1\n",
    "        \n",
    "        # 2. Proyección (Matemática de POS)\n",
    "        # S1 = G - B\n",
    "        # S2 = G + B - 2R\n",
    "        # Ojo: OpenCV entrega BGR, así que índices: 0=B, 1=G, 2=R\n",
    "        S1 = Cn[1, :] - Cn[0, :]\n",
    "        S2 = Cn[1, :] + Cn[0, :] - 2 * Cn[2, :]\n",
    "        \n",
    "        # 3. Fusión Alpha\n",
    "        std_s1 = np.std(S1)\n",
    "        std_s2 = np.std(S2)\n",
    "        alpha = std_s1 / (std_s2 + 1e-6)\n",
    "        \n",
    "        P = S1 + alpha * S2\n",
    "        \n",
    "        return P\n",
    "\n",
    "    def compute_heart_rate(self):\n",
    "        if len(self.rgb_buffer) < self.BUFFER_SIZE:\n",
    "            return\n",
    "\n",
    "        # Convertir buffer a array\n",
    "        rgb_data = np.array(self.rgb_buffer) # (Frames, 3)\n",
    "        times = np.array(self.times_buffer)\n",
    "        \n",
    "        # Calcular FPS reales dinámicos\n",
    "        elapsed = times[-1] - times[0]\n",
    "        fs = len(times) / elapsed if elapsed > 0 else 30.0\n",
    "        \n",
    "        # --- A. Aplicar Algoritmo POS ---\n",
    "        ppg_signal = self.pos_algorithm(rgb_data)\n",
    "        \n",
    "        # --- B. Filtrado (Bandpass Butterworth) ---\n",
    "        # Filtramos entre 0.7 Hz (42 BPM) y 3.5 Hz (210 BPM)\n",
    "        nyquist = fs / 2\n",
    "        low = 0.7 / nyquist\n",
    "        high = 3.5 / nyquist\n",
    "        b, a = signal.butter(3, [low, high], btype='band')\n",
    "        filtered_ppg = signal.filtfilt(b, a, ppg_signal)\n",
    "        \n",
    "        # --- C. FFT (Fourier) ---\n",
    "        N = len(filtered_ppg)\n",
    "        yf = rfft(filtered_ppg)\n",
    "        xf = rfftfreq(N, 1 / fs)\n",
    "        \n",
    "        # Máscara para rango humano\n",
    "        mask = (xf >= 0.7) & (xf <= 3.5)\n",
    "        valid_xf = xf[mask]\n",
    "        valid_yf = np.abs(yf[mask])\n",
    "        \n",
    "        if len(valid_yf) > 0:\n",
    "            peak_idx = np.argmax(valid_yf)\n",
    "            freq_hz = valid_xf[peak_idx]\n",
    "            new_bpm = freq_hz * 60\n",
    "            \n",
    "            # Suavizado de la lectura (Media móvil)\n",
    "            self.bpm_history.append(new_bpm)\n",
    "            if len(self.bpm_history) > 10: # Guardar últimos 10 cálculos\n",
    "                self.bpm_history.pop(0)\n",
    "            \n",
    "            self.current_bpm = np.mean(self.bpm_history)\n",
    "            self.is_stable = True\n",
    "\n",
    "    def run(self):\n",
    "        cap = self.setup_camera()\n",
    "        print(\"Iniciando Sistema Biométrico Robusto...\")\n",
    "        print(\"Manten tu cara iluminada y dentro de los recuadros verdes.\")\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            curr_time = time.time()\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.face_mesh.process(rgb_frame)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    # 1. Obtener color promedio (Frente + Mejillas)\n",
    "                    # Ojo: get_multi_roi_color devuelve BGR porque usa 'frame' original\n",
    "                    bgr_val = self.get_multi_roi_color(frame, face_landmarks)\n",
    "                    \n",
    "                    # 2. Actualizar Buffers\n",
    "                    self.rgb_buffer.append(bgr_val)\n",
    "                    self.times_buffer.append(curr_time)\n",
    "                    \n",
    "                    # Mantener tamaño fijo (FIFO)\n",
    "                    if len(self.rgb_buffer) > self.BUFFER_SIZE:\n",
    "                        self.rgb_buffer.pop(0)\n",
    "                        self.times_buffer.pop(0)\n",
    "                    \n",
    "                    # 3. Procesar señal (cada X frames para ahorrar CPU)\n",
    "                    if len(self.rgb_buffer) == self.BUFFER_SIZE and len(self.rgb_buffer) % 2 == 0:\n",
    "                        self.compute_heart_rate()\n",
    "\n",
    "                    # --- INTERFAZ VISUAL ---\n",
    "                    # Barra de progreso de captura\n",
    "                    if not self.is_stable:\n",
    "                        progress = int((len(self.rgb_buffer) / self.BUFFER_SIZE) * 100)\n",
    "                        cv2.putText(frame, f\"Calibrando: {progress}%\", (20, 50), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                    else:\n",
    "                        # Mostrar BPM\n",
    "                        color_bpm = (0, 255, 0) if 60 < self.current_bpm < 100 else (0, 165, 255)\n",
    "                        cv2.putText(frame, f\"BPM: {self.current_bpm:.1f}\", (20, 60), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, color_bpm, 3)\n",
    "                        cv2.putText(frame, \"Algoritmo: POS + Multi-ROI\", (20, 90), \n",
    "                                    cv2.FONT_HERSHEY_PLAIN, 1, (200, 200, 200), 1)\n",
    "\n",
    "            else:\n",
    "                # Resetear si se pierde la cara\n",
    "                self.rgb_buffer = []\n",
    "                self.times_buffer = []\n",
    "                self.is_stable = False\n",
    "                cv2.putText(frame, \"NO FACE DETECTED\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow('TFG - Biometria Avanzada', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = RobustHeartRateDetector()\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rPPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

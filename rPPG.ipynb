{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277c95df",
   "metadata": {},
   "source": [
    "# **REMOTE PHOTOPLETHYSMOGRAPHY (rPPG)**\n",
    "\n",
    "## IMPORTS Y CREACIÓN DEL ENTORNO PARA EL PROYECTO\n",
    "\n",
    "Se va a crear un nuevo environment utilizando **_Anaconda Prompt_** con las dependencias necesarias y únicas para la correcta realización del proyecto."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6f932a7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "conda create --name rPPG python=3.10\n",
    "conda activate rPPG\n",
    "pip install opencv-python mediapipe numpy scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef67df",
   "metadata": {},
   "source": [
    "Ya con las instalaciones y el environment creado, se va a proceder a la importación de las librerías necesarias para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62c0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import signal\n",
    "from scipy.fft import rfft, rfftfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc28cb",
   "metadata": {},
   "source": [
    "## REMOTE HEARD FRECUENCY\n",
    "\n",
    "Se va a capturar la frecuencia cardiaca a través de la WebCam del dispositivo.\n",
    "\n",
    "**Limitaciones y Consideraciones técnicas:**\n",
    "\n",
    "Aunque el sistema implementa algoritmos robustos como **POS (Plane-Orthogonal-to-Skin)** y segmentación **Multi-ROI**, la fotoplestimografía remota presenta limitaciones inherentes que dependen del entorno y la fisiología del sujeto.\n",
    "\n",
    "- **Iluminación y Relación Señal-Ruido (SNR):** El sistema no mide directamente el flujo sanguíneo, sino las variaciones sutiles en la absorción de luz. Por tanto, la calidad de la señal depende estrictamente de la fuente lumínica:\n",
    "\n",
    "    - **Baja iluminación:** El sensor de la cámara aumenta ganancia (ISO) automáticamente, introduciendo ruido de disparo (shot noise) y ruido térmico granular que enmascara la componente AC (pulsátil) de la señal cardíaca.\n",
    "\n",
    "    - **_Aliasing_ por iluminación artificial:** Fuentes de luz fluorescente aintiguas con parpadeo perceptible (50/60Hz) pueden introducir armónicos en el espectro de frecuencias que, por *aliasing* se podrían interpretar como latidos cardíacos si no se filtran adecuadamente.\n",
    "\n",
    "- **Variabilidad fisiológica y fototipos de piel:** La eficacia del algoritmo varía según diferentes grupos étnicos y características físicas del sujeto:\n",
    "\n",
    "    - **Fototipos altos:** Las pieles con mayor concentración de melanina absorben mayor cantidad de luz, reduciendo así la intensidad de la luz reflejada y disminuyendo en consecuencia la amplitud de la señal PPG. El resultado de lo anterior es que la **Relación Señal-Ruido (SNR)** es más baja comparada a la obtenida en pieles claras. Como solución, se puede implementar mayor iluminación o que la misma sea más intensa para obtener resultados fiables.\n",
    "\n",
    "    - **Oclusiones faciales:** El modelo utiliza tanto la frente como las mejillas, por lo tanto, si el individuo posee vello facial denso, gafas de montura muy gruesa, flequillos o cualquier objeto que interfiera directamente en estas zonas, se reduce el área efectiva de la ROI (Región de Interés).\n",
    "\n",
    "- **Artefactos de movimiento:** Aunque se implementa el algormito de proyección ortogonal (POS), si se suceden movimientos bruscos como hablar o gesticular se introducen cambios no lineales en la reflexión de la luz que no pueden ser cancelados totalmente por el modelo matemático lineal.\n",
    "\n",
    "    - **Restricción:** El individuo debe mantenerse a una posición relativamente estática para garantizar una precisión óptima.\n",
    "\n",
    "- **Latencia en la inicialización:** El sistema hace uso de un buffer temporal para realizar el análisis en el dominio de la frecuencia (FFT).\n",
    "\n",
    "    - **Cold Start:** El sistema tiene un retardo inicial de aproximadamente 5/6 segundos (viene dado por el tamaño del buffer) desde que se detecta la cara hasta que se encuentra el primer dato fiable, impidiendo así la medición instantánea.\n",
    "\n",
    "- **Limitaciones Hardware:**\n",
    "\n",
    "    - **Compresión de Video:** Muchas webcams comprimen el video en tiempo real. Los artefactos de compresión pueden alterar lso valores de color de los píxeles, suavisando los micro-cambios de color necesarios para la rPPG.\n",
    "\n",
    "    - **Jitter de FPS:** Si la CPU está saturada, la tasa de frames puede no ser constante. Aunque el código recalcula lso FPS dinámicamente, caídas drásticas afectarán la precisión de la **Transformada de Fourier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b78dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema Iniciado...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanp\\anaconda3\\envs\\rPPG\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from scipy import signal\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "class RobustHeartRateDetector:\n",
    "    def __init__(self):\n",
    "        # --- CONFIGURACIÓN DE MEDIAPIPE ---\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=False, # True consume más CPU, False está bien para rPPG\n",
    "            min_detection_confidence=0.6,\n",
    "            min_tracking_confidence=0.6\n",
    "        )\n",
    "        \n",
    "        # --- PARÁMETROS DEL SISTEMA ---\n",
    "        self.BUFFER_SIZE = 180     # Aumentado a ~6 segundos (mejor resolución de frecuencia)\n",
    "        self.FS_TARGET = 30.0      # Frecuencia de muestreo objetivo para interpolación\n",
    "        \n",
    "        # Buffers\n",
    "        self.rgb_buffer = [] \n",
    "        self.times_buffer = [] \n",
    "        self.bpm_history = [] \n",
    "        \n",
    "        self.current_bpm = 0.0\n",
    "        self.is_stable = False\n",
    "        self.snr = 0.0             # Relación Señal-Ruido para validar calidad\n",
    "\n",
    "    def setup_camera(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        # Nota: En Windows/DirectShow, usar números negativos grandes para manual\n",
    "        cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25) \n",
    "        cap.set(cv2.CAP_PROP_EXPOSURE, -4.0) \n",
    "        cap.set(cv2.CAP_PROP_AUTOFOCUS, 0)\n",
    "        return cap\n",
    "\n",
    "    def get_roi_average(self, frame, landmarks):\n",
    "        \"\"\"\n",
    "        Versión optimizada que usa coordenadas de landmarks.\n",
    "        En lugar de dibujar máscaras complejas, tomamos puntos clave.\n",
    "        Como se usan distancias fihas, esto es mucho más rápido que sacar máscaras completas\n",
    "        \"\"\"\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Índices de Mejillas y Frente (Simplificado para velocidad)\n",
    "        # Frente: 10, Mejilla I: 330, Mejilla D: 101 (aprox centros)\n",
    "        roi_centers = [10, 330, 101] \n",
    "        roi_size = int(w * 0.08) # Tamaño dinámico según ancho de imagen\n",
    "        \n",
    "        accum_color = np.array([0.0, 0.0, 0.0])\n",
    "        count = 0\n",
    "\n",
    "        for idx in roi_centers:\n",
    "            pt = landmarks.landmark[idx]\n",
    "            cx, cy = int(pt.x * w), int(pt.y * h)\n",
    "            \n",
    "            # Clipping seguro\n",
    "            x1 = max(0, cx - roi_size)\n",
    "            y1 = max(0, cy - roi_size)\n",
    "            x2 = min(w, cx + roi_size)\n",
    "            y2 = min(h, cy + roi_size)\n",
    "            \n",
    "            # Extraer crop y calcular media (mucho más rápido que máscaras completas)\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            if crop.size > 0:\n",
    "                mean = np.mean(crop, axis=(0, 1)) # BGR\n",
    "                accum_color += mean\n",
    "                count += 1\n",
    "                \n",
    "                # Visualización (Debug)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        if count > 0:\n",
    "            return accum_color / count\n",
    "        return np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    def pos_algorithm(self, rgb_array):\n",
    "        \"\"\" Algoritmo POS optimizado con NumPy \"\"\"\n",
    "        # rgb_array: (N, 3)\n",
    "        # Normalización temporal\n",
    "        mean_color = np.mean(rgb_array, axis=0)\n",
    "        Cn = rgb_array / (mean_color + 1e-6) - 1\n",
    "        \n",
    "        # Proyección\n",
    "        # Cn columns: 0=B, 1=G, 2=R (OpenCV standard)\n",
    "        r = Cn[:, 2]\n",
    "        g = Cn[:, 1]\n",
    "        b = Cn[:, 0]\n",
    "        \n",
    "        S1 = g - b\n",
    "        S2 = g + b - 2*r\n",
    "        \n",
    "        # Fusión Alpha con manejo de división por cero\n",
    "        std_s1 = np.std(S1)\n",
    "        std_s2 = np.std(S2)\n",
    "        alpha = std_s1 / (std_s2 + 1e-6)\n",
    "        \n",
    "        P = S1 + alpha * S2\n",
    "        return P\n",
    "\n",
    "    def compute_heart_rate(self):\n",
    "        if len(self.rgb_buffer) < self.BUFFER_SIZE:\n",
    "            return\n",
    "\n",
    "        # 1. Obtener datos crudos\n",
    "        raw_rgb = np.array(self.rgb_buffer) # (Frames, 3)\n",
    "        raw_times = np.array(self.times_buffer)\n",
    "        \n",
    "        # --- INTERPOLACIÓN ---\n",
    "        # Las cámaras no capturan a intervalos perfectos. Interpolar a FS_TARGET (30Hz).\n",
    "        raw_times = raw_times - raw_times[0] # Empezar en t=0\n",
    "        \n",
    "        if raw_times[-1] <= 0: return # Evitar errores de tiempo cero\n",
    "\n",
    "        # Crear eje de tiempo uniforme\n",
    "        num_samples = int(raw_times[-1] * self.FS_TARGET)\n",
    "        uniform_times = np.linspace(0, raw_times[-1], num_samples)\n",
    "        \n",
    "        # Interpolar cada canal (R, G, B)\n",
    "        interpolated_rgb = np.zeros((num_samples, 3))\n",
    "        for i in range(3):\n",
    "            f_interp = interp1d(raw_times, raw_rgb[:, i], kind='linear', fill_value=\"extrapolate\")\n",
    "            interpolated_rgb[:, i] = f_interp(uniform_times)\n",
    "\n",
    "        # 2. Aplicar POS sobre datos interpolados\n",
    "        ppg_signal = self.pos_algorithm(interpolated_rgb)\n",
    "        \n",
    "        # 3. Detrending (Quitar tendencias de iluminación lenta)\n",
    "        ppg_signal = signal.detrend(ppg_signal)\n",
    "        \n",
    "        # 4. Filtrado Bandpass (Butterworth)\n",
    "        # Rango 42 BPM (0.7Hz) a 180 BPM (3.0Hz)\n",
    "        nyquist = self.FS_TARGET / 2\n",
    "        b, a = signal.butter(3, [0.7/nyquist, 3.0/nyquist], btype='band')\n",
    "        filtered_ppg = signal.filtfilt(b, a, ppg_signal)\n",
    "        \n",
    "        # --- VENTANEO (WINDOWING) ---\n",
    "        # Reduce fugas espectrales en la FFT\n",
    "        window = np.hanning(len(filtered_ppg))\n",
    "        windowed_signal = filtered_ppg * window\n",
    "        \n",
    "        # 5. FFT\n",
    "        N = len(windowed_signal)\n",
    "        yf = rfft(windowed_signal)\n",
    "        xf = rfftfreq(N, 1 / self.FS_TARGET)\n",
    "        \n",
    "        # Buscar picos en rango humano\n",
    "        mask = (xf >= 0.7) & (xf <= 3.0)\n",
    "        valid_xf = xf[mask]\n",
    "        valid_yf = np.abs(yf[mask])\n",
    "        \n",
    "        if len(valid_yf) > 0:\n",
    "            peak_idx = np.argmax(valid_yf)\n",
    "            freq_hz = valid_xf[peak_idx]\n",
    "            peak_val = valid_yf[peak_idx]\n",
    "            \n",
    "            # --- CALCULO DE SNR (Calidad de señal) ---\n",
    "            # SNR = Energía del pico / Energía del ruido circundante\n",
    "            avg_noise = np.mean(valid_yf)\n",
    "            self.snr = peak_val / (avg_noise + 1e-6)\n",
    "            \n",
    "            new_bpm = freq_hz * 60.0\n",
    "            \n",
    "            # Solo actualizar si el SNR es decente (evita ruido aleatorio)\n",
    "            if self.snr > 1.5: # Umbral empírico\n",
    "                self.bpm_history.append(new_bpm)\n",
    "                if len(self.bpm_history) > 12: \n",
    "                    self.bpm_history.pop(0)\n",
    "                \n",
    "                # Media ponderada (dar más peso a las últimas lecturas)\n",
    "                self.current_bpm = np.mean(self.bpm_history)\n",
    "                self.is_stable = True\n",
    "            else:\n",
    "                self.is_stable = False # Señal ruidosa\n",
    "\n",
    "    def estimate_distance_and_check(self, frame, landmarks):\n",
    "        \"\"\"\n",
    "        Calcula la distancia aproximada usuario-cámara basándose en la distancia interpupilar.\n",
    "        Devuelve (distancia_cm, estado_texto, color_estado)\n",
    "        \"\"\"\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Landmarks de las esquinas exteriores de los ojos\n",
    "        # 33: Ojo izquierdo (esquina ext), 263: Ojo derecho (esquina ext)\n",
    "        left_eye = landmarks.landmark[33]\n",
    "        right_eye = landmarks.landmark[263]\n",
    "        \n",
    "        # Calcular distancia en píxeles entre los ojos\n",
    "        x1, y1 = left_eye.x * w, left_eye.y * h\n",
    "        x2, y2 = right_eye.x * w, right_eye.y * h\n",
    "        pixel_dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        \n",
    "        # --- CALIBRACIÓN APROXIMADA ---\n",
    "        # Ancho real promedio entre esquinas de ojos humanos: ~11.5 cm\n",
    "        # Distancia Focal: ~600 es un valor estándar para webcams a 640x480.\n",
    "        # Si usas HD (1280x720), ajusta esto a aprox 1100-1200.\n",
    "        # Fórmula: F = (P * D) / W -> F = (pixel_dist * distancia_conocida) / ancho_real\n",
    "        REAL_EYE_WIDTH = 11.5 # cm\n",
    "        FOCAL_LENGTH = 640    # Ajustar según tu cámara (prueba y error)\n",
    "        \n",
    "        if pixel_dist == 0: return 0, \"Error\", (0,0,255)\n",
    "        \n",
    "        distance_cm = (REAL_EYE_WIDTH * FOCAL_LENGTH) / pixel_dist\n",
    "        \n",
    "        # Definir zonas\n",
    "        if distance_cm < 45:\n",
    "            return distance_cm, \"Muy Cerca\", (0, 0, 255) # Rojo\n",
    "        elif distance_cm > 80:\n",
    "            return distance_cm, \"Muy Lejos\", (0, 165, 255) # Naranja\n",
    "        else:\n",
    "            return distance_cm, \"Distancia Optima\", (0, 255, 0) # Verde\n",
    "\n",
    "    def run(self):\n",
    "            cap = self.setup_camera()\n",
    "            print(\"Sistema Iniciado...\")\n",
    "    \n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret: break\n",
    "    \n",
    "                curr_time = time.time()\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.face_mesh.process(rgb_frame)\n",
    "    \n",
    "                if results.multi_face_landmarks:\n",
    "                    for face_landmarks in results.multi_face_landmarks:\n",
    "                        \n",
    "                        # --- NUEVO: CALCULAR DISTANCIA ---\n",
    "                        dist_cm, status_text, status_color = self.estimate_distance_and_check(frame, face_landmarks)\n",
    "                        \n",
    "                        # Dibujar UI de Distancia\n",
    "                        cv2.putText(frame, f\"Dist: {int(dist_cm)}cm ({status_text})\", (20, 30), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)\n",
    "    \n",
    "                        # --- LÓGICA DE CONTROL ---\n",
    "                        # Solo procesamos el ritmo cardiaco si la distancia es aceptable\n",
    "                        # Esto evita meter ruido en el buffer cuando te acercas/alejas mucho\n",
    "                        if status_text == \"Distancia Optima\":\n",
    "                            \n",
    "                            bgr_val = self.get_roi_average(frame, face_landmarks)\n",
    "                            self.rgb_buffer.append(bgr_val)\n",
    "                            self.times_buffer.append(curr_time)\n",
    "                            \n",
    "                            if len(self.rgb_buffer) > self.BUFFER_SIZE:\n",
    "                                self.rgb_buffer.pop(0)\n",
    "                                self.times_buffer.pop(0)\n",
    "                            \n",
    "                            if len(self.rgb_buffer) == self.BUFFER_SIZE and (len(self.rgb_buffer) % 10 == 0):\n",
    "                                self.compute_heart_rate()\n",
    "    \n",
    "                            # Mostrar BPM solo si estamos en rango\n",
    "                            if self.is_stable:\n",
    "                                cv2.putText(frame, f\"BPM: {self.current_bpm:.1f}\", (20, 70), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "                                cv2.putText(frame, f\"SNR: {self.snr:.2f}\", (20, 100), \n",
    "                                            cv2.FONT_HERSHEY_PLAIN, 1, (200, 200, 200), 1)\n",
    "                            else:\n",
    "                                cv2.putText(frame, \"Calculando...\", (20, 70), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                        else:\n",
    "                            # Si la distancia es mala, mostramos aviso grande\n",
    "                            cv2.putText(frame, \"AJUSTA DISTANCIA\", (int(frame.shape[1]/2)-100, int(frame.shape[0]/2)), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 3)\n",
    "                            \n",
    "                            # Opcional: Reiniciar buffers si el usuario se mueve demasiado para evitar falsos picos\n",
    "                            if len(self.rgb_buffer) > 0:\n",
    "                                self.rgb_buffer.pop(0) \n",
    "                                self.times_buffer.pop(0)\n",
    "    \n",
    "                else:\n",
    "                    self.rgb_buffer.clear()\n",
    "                    self.times_buffer.clear()\n",
    "                    self.is_stable = False\n",
    "                    cv2.putText(frame, \"NO FACE\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "                cv2.imshow('Robust rPPG', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "    \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = RobustHeartRateDetector()\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rPPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
